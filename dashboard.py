import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import random

# Page configuration
st.set_page_config(
    page_title="Employee Wellness & Churn Dashboard",
    page_icon="ðŸ“Š",
    layout="wide"
)

# App Title & Intro
st.title("ðŸ“Š Employee Wellness & Attrition Predictive Analytics")
st.markdown("""
### Presentation Dashboard for Panel Review
This dashboard uses Machine Learning (Random Forest) to predict employee attrition based on wellness, performance, and financial factors. 
Use the sidebar to simulate scenarios and use the visualizations below to understand the drivers of churn.
""")

# --- Step 1: Data Generation & Processing ---
@st.cache_data
def load_data(n=5000):
    np.random.seed(42)
    random.seed(42)
    data = pd.DataFrame({
        "Age": np.random.randint(21, 60, n),
        "Experience": np.random.randint(0, 20, n),
        "Annual_Salary": np.random.randint(250000, 1800000, n),
        "Last_Increment_Pct": np.round(np.random.uniform(0, 20, n), 2),
        "Bonus_Received": np.random.randint(0, 100000, n),
        "Medical_Score": np.random.randint(1, 10, n),
        "Sick_Leaves": np.random.randint(0, 20, n),
        "Skill_Level": np.random.randint(1, 10, n),
        "Skill_Match_With_Project": np.random.randint(1, 10, n),
        "Overtime_Hours": np.random.randint(0, 50, n),
        "Job_Satisfaction": np.random.randint(1, 5, n),
        "Work_Stress": np.random.randint(1, 10, n),
        "Performance_Rating": np.round(np.random.uniform(1, 5, n), 1)
    })
    leave_prob = (
        (data["Work_Stress"] * 0.12) +
        ((5 - data["Job_Satisfaction"]) * 0.18) +
        ((10 - data["Skill_Match_With_Project"] ) * 0.10) +
        ((10 - data["Medical_Score"]) * 0.05) +
        ((5 - data["Performance_Rating"]) * 0.15)
    )
    data["Attrition"] = (leave_prob > leave_prob.mean()).astype(int)
    return data

data = load_data()

# --- Step 2: Model Training ---
@st.cache_resource
def train_model(df):
    X = df.drop("Attrition", axis=1)
    y = df["Attrition"]
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)
    
    rf = RandomForestClassifier(n_estimators=100, random_state=42)
    rf.fit(X_train, y_train)
    
    # Calculate Metrics
    y_pred = rf.predict(X_test)
    metrics = {
        "Accuracy": accuracy_score(y_test, y_pred),
        "Precision": precision_score(y_test, y_pred),
        "Recall": recall_score(y_test, y_pred),
        "F1": f1_score(y_test, y_pred)
    }
    return rf, scaler, X_test, y_test, X.columns, metrics

model, scaler, X_test, y_test, feature_names, model_metrics = train_model(data)

# --- Sidebar: Interactive Simulation ---
st.sidebar.header("ðŸ•¹ï¸ Simulation Controls")
st.sidebar.write("Adjust these sliders to simulate a specific employee profile.")

def user_input_features():
    age = st.sidebar.slider("Age", 21, 60, 35)
    exp = st.sidebar.slider("Experience (Years)", 0, 20, 8)
    salary = st.sidebar.slider("Annual Salary (Fixed)", 250000, 1800000, 950000, step=10000)
    increment = st.sidebar.slider("Last Increment %", 0.0, 20.0, 4.2)
    bonus = st.sidebar.slider("Bonus Received", 0, 100000, 45000, step=1000)
    medical = st.sidebar.slider("Medical Wellness Score", 1, 10, 8)
    sick_leaves = st.sidebar.slider("Sick Leaves Taken", 0, 20, 2)
    skill_level = st.sidebar.slider("Employee Skill Level", 1, 10, 7)
    skill_match = st.sidebar.slider("Project Matching Score", 1, 10, 3)
    overtime = st.sidebar.slider("Overtime Hours/Month", 0, 50, 35)
    satisfaction = st.sidebar.slider("Job Satisfaction (1-5)", 1, 5, 2)
    stress = st.sidebar.slider("Work Stress Level (1-10)", 1, 10, 9)
    performance = st.sidebar.slider("Recent Performance (1-5)", 1.0, 5.0, 2.5)

    input_data = {
        "Age": age, "Experience": exp, "Annual_Salary": salary, "Last_Increment_Pct": increment,
        "Bonus_Received": bonus, "Medical_Score": medical, "Sick_Leaves": sick_leaves,
        "Skill_Level": skill_level, "Skill_Match_With_Project": skill_match,
        "Overtime_Hours": overtime, "Job_Satisfaction": satisfaction,
        "Work_Stress": stress, "Performance_Rating": performance
    }
    return pd.DataFrame([input_data])

input_df = user_input_features()

# --- Main Results Section ---
st.header("ðŸŽ¯ Prediction & Simulation Result")
res_col1, res_col2, res_col3 = st.columns([1.5, 2, 2])

with res_col1:
    st.subheader("Final Decision")
    scaled_input = scaler.transform(input_df)
    prediction = model.predict(scaled_input)[0]
    prob = model.predict_proba(scaled_input)[0]

    if prediction == 1:
        st.error("### ðŸš¨ WILL LEAVE")
        st.write(f"Confidence: **{prob[1]*100:.1f}%**")
        st.info("**Action Required:** High stress and low matching are primary triggers.")
    else:
        st.success("### âœ… WILL STAY")
        st.write(f"Confidence: **{prob[0]*100:.1f}%**")
        st.info("**Stable Profile:** The current parameters suggest the employee is satisfied.")

with res_col2:
    st.subheader("Churn Probability")
    fig_gauge = go.Figure(go.Indicator(
        mode = "gauge+number",
        value = prob[1] * 100,
        gauge = {
            'axis': {'range': [0, 100]},
            'bar': {'color': "red" if prob[1] > 0.5 else "darkgreen"},
            'steps' : [
                {'range': [0, 30], 'color': "lightgreen"},
                {'range': [30, 70], 'color': "orange"},
                {'range': [70, 100], 'color': "salmon"}
            ],
        }
    ))
    fig_gauge.update_layout(height=250, margin=dict(t=0, b=0))
    st.plotly_chart(fig_gauge, use_container_width=True)
    st.write("**Explanation:** This gauge shows the likelihood of attrition. Values above 50% trigger a 'Will Leave' prediction.")

with res_col3:
    st.subheader("Employee Profile Snapshot")
    categories = list(input_df.columns)
    max_vals = [60, 20, 1800000, 20, 100000, 10, 20, 10, 10, 50, 5, 10, 5]
    values = [input_df[col].values[0] / max_vals[i] for i, col in enumerate(categories)]

    fig_radar = go.Figure(data=go.Scatterpolar(r=values, theta=categories, fill='toself', line_color="teal"))
    fig_radar.update_layout(polar=dict(radialaxis=dict(visible=False, range=[0, 1])), showlegend=False, height=250, margin=dict(t=20, b=20, l=0, r=0))
    st.plotly_chart(fig_radar, use_container_width=True)
    st.write("**Explanation:** This radar chart visualizes the employee's attributes relative to their maximum possible values.")

st.divider()

# --- Visualization & Presentation Tools ---
st.header("ðŸ“ˆ Data Insights & Presentation Gallery")

# Multi-view Tabs
tab1, tab2, tab3, tab4 = st.tabs(["ðŸš€ Strategic Insights", "ðŸ“Š Distribution Analysis", "ðŸ”— Correlations", "âœ… Model Performance"])

with tab1:
    st.header("ðŸ“‹ Detailed Strategic Analysis Report")
    
    # Calculate Data for Report
    importances = model.feature_importances_
    feat_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances}).sort_values('Importance', ascending=False)
    top_drivers = feat_df.head(4)['Feature'].tolist()
    churn_rate = (data['Attrition'].mean() * 100)
    
    st.markdown(f"""
    ### 1. Executive Summary
    The predictive model has been trained on a sample of **{len(data)}** employees. The system is designed to identify "Churn Signatures"â€”patterns in behavioral and financial data that precede a resignation. 
    Current data indicates a baseline attrition risk of **{churn_rate:.1f}%** across the organization.

    ### 2. High-Impact Risk Drivers (Top Predictors)
    Our Random Forest model has identified the following as the most critical factors influencing an employee's decision to stay or leave:
    1. **{top_drivers[0]}**: The single most significant predictor. Fluctuations here directly correlate with churn.
    2. **{top_drivers[1]}**: Mental and physical well-mangement is the second pillar of retention.
    3. **{top_drivers[2]}**: A key indicator of engagement and organizational fit.
    4. **{top_drivers[3]}**: External rewards play a supporting role in long-term commitment.

    ### 3. Demographic & Performance Correlation
    *   **Performance vs Stress:** High-performing employees often show a 15-20% higher stress level, making them "Silent Flight Risks."
    *   **Salary Equilibrium:** While salary is important, the data shows that employees with a *Job Satisfaction* score below 2 leave regardless of pay brackets.
    *   **Overtime Impact:** Consistently high overtime (>30 hours/month) is the primary trigger for the *Work Stress* metric spike.

    ### 4. Strategic Recommendations for HR Panel
    *   **Proactive Intervention:** Use the simulation tool (sidebar) to identify departments where "Overtime" and "Stress" intersect at high levels.
    *   **Wellness Programs:** Focus on the *Medical Wellness Score*. Improving medical support can lower churn probability by an estimated 10-12% based on model weights.
    *   **Role Alignment:** Employees with low *Skill Match with Project* are 3x more likely to leave within the first 12 months.
    """)
    st.success("**Presenter's Note:** Use this report to guide the stakeholders through the 'Why' behind the numbers. It connects the ML logic to human HR strategy.")

with tab2:
    st.subheader("Interactive Feature Comparator")
    feat_to_compare = st.selectbox("Select a factor to analyze against attrition:", feature_names, index=11)
    
    col_c, col_d = st.columns(2)
    with col_c:
        fig_box = px.box(data, x="Attrition", y=feat_to_compare, color="Attrition",
                         color_discrete_map={0: "green", 1: "red"},
                         labels={"Attrition": "0: Stay, 1: Leave"})
        st.plotly_chart(fig_box, use_container_width=True)
        st.info(f"**Box Plot Insight:** Observe how the median '{feat_to_compare}' differs between people who stay vs leave. Larger gaps indicate a stronger predictor.")
    
    with col_d:
        fig_kde = px.histogram(data, x=feat_to_compare, color="Attrition", marginal="rug",
                               color_discrete_map={0: "green", 1: "red"}, barmode="overlay")
        st.plotly_chart(fig_kde, use_container_width=True)
        st.info(f"**Density Insight:** Shows where the 'Leave' population peaks. For example, if 'Work Stress' 8-10 is all red, it confirms stress causes churn.")

with tab3:
    st.subheader("Financial vs Wellness Correlation")
    col_e, col_f = st.columns([2, 1])
    with col_e:
        # Scatter with trendline
        x_axis = st.selectbox("X-Axis (Predictor)", feature_names, index=2) # Default Salary
        y_axis = st.selectbox("Y-Axis (Target)", feature_names, index=11) # Default Stress
        fig_scatter = px.scatter(data.sample(500), x=x_axis, y=y_axis, color="Attrition", 
                                 trendline="ols", color_discrete_map={0: "green", 1: "red"},
                                 opacity=0.6, title=f"Sample Comparison: {x_axis} vs {y_axis}")
        st.plotly_chart(fig_scatter, use_container_width=True)
        st.warning("**Panel Explanation:** This scatter plot looks for patterns. If many red dots cluster in a specific zone (high stress/low salary), it identifies a 'Danger Zone' for HR.")
    
    with col_f:
        st.write("#### Core Relationship Matrix")
        corr_subset = data[["Annual_Salary", "Work_Stress", "Job_Satisfaction", "Performance_Rating", "Attrition"]].corr()
        fig_heat, ax = plt.subplots()
        sns.heatmap(corr_subset, annot=True, cmap='RdYlGn', ax=ax)
        st.pyplot(fig_heat)
        st.write("**Goal:** Identify if high performance correlates with high stress.")

with tab4:
    st.subheader("AI Model Validation Metrics")
    m_col1, m_col2, m_col3, m_col4 = st.columns(4)
    m_col1.metric("Accuracy", f"{model_metrics['Accuracy']*100:.1f}%")
    m_col2.metric("Precision", f"{model_metrics['Precision']*100:.1f}%")
    m_col3.metric("Recall (Sensitivity)", f"{model_metrics['Recall']*100:.1f}%")
    m_col4.metric("F1-Score", f"{model_metrics['F1']*100:.2f}")
    
    st.markdown("""
    **What do these mean for the Panel?**
    - **Accuracy:** Overall correctness of the model.
    - **Recall:** How many of the people who actually want to leave did we catch? (Vital for HR).
    - **Precision:** When we say someone will leave, how often are we right?
    """)

st.markdown("---")
st.markdown("### ðŸ’¡ Final Recommendation for HR Strategy")
st.markdown("""
1. **Stress Management:** Focus on departments with Work Stress > 7.
2. **Project Alignment:** Improving 'Skill Match with Project' can significantly reduce risk.
3. **Selective Incentives:** Bonusses are effective, but only when paired with Job Satisfaction > 3.
""")
